{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98060f5a-398e-48cd-97a6-1c3ec921cd8d",
   "metadata": {},
   "source": [
    "## Predictive Analytics for Enhancing Machine Maintenance Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f48ce9ff-2e39-473f-88a7-32726fc09a8e",
   "metadata": {},
   "source": [
    "Team Members : \r\n",
    "1. Penchala Akshay Kumar Kandagaddala\r\n",
    "2. Yogesh Savirigana\r\n",
    "3. Venkata Satya Naveen Nagulapalli\r\n",
    "4. Shashank Rao Gujja\r\n",
    "5. Sudeshna Mullaguru\r\n",
    "6. Vijaya Lakshmi Kalpana Potti"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ae2229-e9cf-4977-9ed3-7e6cc2d4979e",
   "metadata": {},
   "source": [
    "### Business Challenge:\r\n",
    "\r\n",
    "In the modern manufacturing industry, minimizing unplanned downtime caused by equipment failures is of most important. Unplanned downtime can lead to substantial financial losses, decreased productivity, and disrupted operations. To tackle this challenge, manufacturers are embracing predictive maintenance (PdM) solutions. These solutions harness the power of data analytics to predict and prevent potential machine malfunctions before they disrupt production. By analyzing historical data, monitoring equipment in real-time, and utilizing machine learning algorithms, manufacturers can identify patterns and anomalies that signal impending issues. This proactive approach not only saves time and resources but also optimizes efficiency and overall profitability in the manufacturing process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "345d39c3-7f2e-45b0-8018-c608b76de97a",
   "metadata": {},
   "source": [
    "### Problem Statement:\r\n",
    "\r\n",
    "In the highly competitive manufacturing sector, maximizing equipment uptime is a critical factor in maintaining productivity and profitability. Traditional preventive maintenance practices, though well-intentioned, often fall short of ensuring peak equipment performance and minimizing costly downtime. These methods rely on time-based schedules or usage-based thresholds, leading to unnecessary maintenance interventions, increased expenses, and production disruptions.\r\n",
    "\r\n",
    "Predictive maintenance (PdM) is a revolutionary approach to equipment maintenance, shifting the focus from reactive repairs to proactive prevention. By harnessing the potential of data analytics and machine learning, PdM empowers manufacturers to anticipate and forestall machine failures, substantially reducing unplanned downtime and its associated financial burdens.\r\n",
    "\r\n",
    "At the heart of PdM is its capability to accurately predict the likelihood of machine failures and identify potential failure modes. This predictive ability hinges on continuous data collection and analysis from various sensors and monitoring devices installed on critical equipment. These data streams encompass variables such as vibration, temperature, pressure, and other parameters that offer insights into machinery health and condition.\r\n",
    "\r\n",
    "Once a machine failure is anticipated, PdM systems provide comprehensive insights into the most probable type of failure and an estimate of the time remaining until the failure occurs (ETTF). Armed with this vital information, maintenance teams can proactively schedule maintenance activities, addressing potential issues before they disrupt production operations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a6ff37e-14fa-4f9d-adfc-cc3414f0df6b",
   "metadata": {},
   "source": [
    "### Data Source:\n",
    "The data is sourced from the UCI Machine Learning Repository, which can be found in : https://archive.ics.uci.edu/dataset/601/ai4i+2020+predictive+maintenance+dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29118003-c59b-4b27-b02f-9de2c0ad5268",
   "metadata": {},
   "source": [
    "### Dataset Overview:\r\n",
    "\r\n",
    "The Machine Predictive Maintenance Classification Dataset is a synthetic dataset that reflects real predictive maintenance data encountered in industry. It consists of 10,000 data points with 14 features and two primary targets: \"Failure or Not\" and \"Failure Type.\" The dataset is designed to be challenging for machine learning algorithms, as it contains a variety of different failure modes and noise.\r\n",
    "\r\n",
    "14 features\r\n",
    "\r\n",
    "Two primary targets:\r\n",
    "\r\n",
    "\"Failure or Not\": Indicates whether a machine failure has occurred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32a9811-bba6-4fc3-96a5-225c64afcebd",
   "metadata": {},
   "source": [
    "## Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b4ca1b2-3fef-4f0b-97e1-a9f7f8bfdb15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/11/10 03:06:50 WARN Utils: Your hostname, localhost.localdomain resolves to a loopback address: 127.0.0.1; using 10.21.11.132 instead (on interface eth0)\n",
      "23/11/10 03:06:50 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/11/10 03:06:51 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark Session WebUI Port: 4040\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession;\n",
    "\n",
    "# warehouse_location points to the default location for managed databases and tables\n",
    "from os.path import abspath\n",
    "warehouse_location = abspath('spark-warehouse')\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName(\"ISM6562 PySpark Tutorials\") \\\n",
    "    .config(\"spark.sql.warehouse.dir\", warehouse_location) \\\n",
    "    .enableHiveSupport() \\\n",
    "    .getOrCreate()\n",
    "\n",
    "\n",
    "# Let's get the SparkContext object. It's the entry point to the Spark API. It's created when you create a sparksession\n",
    "sc = spark.sparkContext\n",
    "\n",
    "# note: If you have multiple spark sessions running (like from a previous notebook you've run), \n",
    "# this spark session webUI will be on a different port than the default (4040). One way to \n",
    "# identify this part is with the following line. If there was only one spark session running, \n",
    "# this will be 4040. If it's higher, it means there are still other spark sesssions still running.\n",
    "spark_session_port = spark.sparkContext.uiWebUrl.split(\":\")[-1]\n",
    "print(\"Spark Session WebUI Port: \" + spark_session_port)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7d67606-aae3-463c-8e47-7427a55bebd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://linux:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>ISM6562 PySpark Tutorials</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f29140dad20>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36c7fe70-b133-4df9-9412-1f16d6203acc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+----+-------------------+-----------------------+----------------------+-----------+---------------+---------------+---+---+---+---+---+\n",
      "|UDI|Product ID|Type|Air temperature [K]|Process temperature [K]|Rotational speed [rpm]|Torque [Nm]|Tool wear [min]|Machine failure|TWF|HDF|PWF|OSF|RNF|\n",
      "+---+----------+----+-------------------+-----------------------+----------------------+-----------+---------------+---------------+---+---+---+---+---+\n",
      "|  1|    M14860|   M|              298.1|                  308.6|                  1551|       42.8|              0|              0|  0|  0|  0|  0|  0|\n",
      "|  2|    L47181|   L|              298.2|                  308.7|                  1408|       46.3|              3|              0|  0|  0|  0|  0|  0|\n",
      "|  3|    L47182|   L|              298.1|                  308.5|                  1498|       49.4|              5|              0|  0|  0|  0|  0|  0|\n",
      "|  4|    L47183|   L|              298.2|                  308.6|                  1433|       39.5|              7|              0|  0|  0|  0|  0|  0|\n",
      "|  5|    L47184|   L|              298.2|                  308.7|                  1408|       40.0|              9|              0|  0|  0|  0|  0|  0|\n",
      "+---+----------+----+-------------------+-----------------------+----------------------+-----------+---------------+---------------+---+---+---+---+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType, DateType\n",
    "\n",
    "df = spark.read.csv('data/ai4i2020.csv', header=True, inferSchema=True)\n",
    "\n",
    "# display the first 5 rows of the dataframe\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4aac8fa-7e49-4a87-8a48-b383771bcb96",
   "metadata": {},
   "source": [
    "### Inspect the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5807b716-aa9e-4ac4-85a7-6e5f579f6d8a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- UDI: integer (nullable = true)\n",
      " |-- Product ID: string (nullable = true)\n",
      " |-- Type: string (nullable = true)\n",
      " |-- Air temperature [K]: double (nullable = true)\n",
      " |-- Process temperature [K]: double (nullable = true)\n",
      " |-- Rotational speed [rpm]: integer (nullable = true)\n",
      " |-- Torque [Nm]: double (nullable = true)\n",
      " |-- Tool wear [min]: integer (nullable = true)\n",
      " |-- Machine failure: integer (nullable = true)\n",
      " |-- TWF: integer (nullable = true)\n",
      " |-- HDF: integer (nullable = true)\n",
      " |-- PWF: integer (nullable = true)\n",
      " |-- OSF: integer (nullable = true)\n",
      " |-- RNF: integer (nullable = true)\n",
      "\n",
      "+---+----------+----+-------------------+-----------------------+----------------------+-----------+---------------+---------------+---+---+---+---+---+\n",
      "|UDI|Product ID|Type|Air temperature [K]|Process temperature [K]|Rotational speed [rpm]|Torque [Nm]|Tool wear [min]|Machine failure|TWF|HDF|PWF|OSF|RNF|\n",
      "+---+----------+----+-------------------+-----------------------+----------------------+-----------+---------------+---------------+---+---+---+---+---+\n",
      "|  1|    M14860|   M|              298.1|                  308.6|                  1551|       42.8|              0|              0|  0|  0|  0|  0|  0|\n",
      "|  2|    L47181|   L|              298.2|                  308.7|                  1408|       46.3|              3|              0|  0|  0|  0|  0|  0|\n",
      "|  3|    L47182|   L|              298.1|                  308.5|                  1498|       49.4|              5|              0|  0|  0|  0|  0|  0|\n",
      "|  4|    L47183|   L|              298.2|                  308.6|                  1433|       39.5|              7|              0|  0|  0|  0|  0|  0|\n",
      "|  5|    L47184|   L|              298.2|                  308.7|                  1408|       40.0|              9|              0|  0|  0|  0|  0|  0|\n",
      "|  6|    M14865|   M|              298.1|                  308.6|                  1425|       41.9|             11|              0|  0|  0|  0|  0|  0|\n",
      "|  7|    L47186|   L|              298.1|                  308.6|                  1558|       42.4|             14|              0|  0|  0|  0|  0|  0|\n",
      "|  8|    L47187|   L|              298.1|                  308.6|                  1527|       40.2|             16|              0|  0|  0|  0|  0|  0|\n",
      "|  9|    M14868|   M|              298.3|                  308.7|                  1667|       28.6|             18|              0|  0|  0|  0|  0|  0|\n",
      "| 10|    M14869|   M|              298.5|                  309.0|                  1741|       28.0|             21|              0|  0|  0|  0|  0|  0|\n",
      "| 11|    H29424|   H|              298.4|                  308.9|                  1782|       23.9|             24|              0|  0|  0|  0|  0|  0|\n",
      "| 12|    H29425|   H|              298.6|                  309.1|                  1423|       44.3|             29|              0|  0|  0|  0|  0|  0|\n",
      "| 13|    M14872|   M|              298.6|                  309.1|                  1339|       51.1|             34|              0|  0|  0|  0|  0|  0|\n",
      "| 14|    M14873|   M|              298.6|                  309.2|                  1742|       30.0|             37|              0|  0|  0|  0|  0|  0|\n",
      "| 15|    L47194|   L|              298.6|                  309.2|                  2035|       19.6|             40|              0|  0|  0|  0|  0|  0|\n",
      "| 16|    L47195|   L|              298.6|                  309.2|                  1542|       48.4|             42|              0|  0|  0|  0|  0|  0|\n",
      "| 17|    M14876|   M|              298.6|                  309.2|                  1311|       46.6|             44|              0|  0|  0|  0|  0|  0|\n",
      "| 18|    M14877|   M|              298.7|                  309.2|                  1410|       45.6|             47|              0|  0|  0|  0|  0|  0|\n",
      "| 19|    H29432|   H|              298.8|                  309.2|                  1306|       54.5|             50|              0|  0|  0|  0|  0|  0|\n",
      "| 20|    M14879|   M|              298.9|                  309.3|                  1632|       32.5|             55|              0|  0|  0|  0|  0|  0|\n",
      "+---+----------+----+-------------------+-----------------------+----------------------+-----------+---------------+---------------+---+---+---+---+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a5e11fb-cb21-4d5c-bea9-c23721cbed31",
   "metadata": {},
   "source": [
    "#### Column Descriptions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d82a5d-3005-4069-a1d2-853c9b1f81b0",
   "metadata": {},
   "source": [
    "| Column Name               | Description |\n",
    "|---------------------------|-------------|\n",
    "| `UDI`                     | Unique identifier for each record. |\n",
    "| `Product ID`              | Identifier for the product. |\n",
    "| `Type`                    | The type of the product. |\n",
    "| `Air temperature [K]`     | Ambient air temperature measured in Kelvin. |\n",
    "| `Process temperature [K]` | Temperature of the process, measured in Kelvin. |\n",
    "| `Rotational speed [rpm]`  | Speed at which the machine operates, measured in revolutions per minute. |\n",
    "| `Torque [Nm]`             | The torque produced by the machine, measured in Newton meters. |\n",
    "| `Tool wear [min]`         | The amount of wear on the tool, measured in minutes. |\n",
    "| `Machine failure`         | Indicates if there was a machine failure (1) or not (0). |\n",
    "| `TWF`                     | Tool Wear Failure - Indicates if the failure was due to tool wear. |\n",
    "| `HDF`                     | Heat Dissipation Failure - Indicates if the failure was due to heat dissipation. |\n",
    "| `PWF`                     | Power Failure - Indicates if the failure was due to power failure. |\n",
    "| `OSF`                     | Overstrain Failure - Indicates if the failure was due to overstrain. |\n",
    "| `RNF`                     | Random Failures - Indicates if the failure was random. |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5dc543-12bf-4bde-9092-54231c00eda0",
   "metadata": {},
   "source": [
    "| Column Name               | Description |\n",
    "|---------------------------|-------------|\n",
    "| `UDI`                     | Unique identifier for each record. |\n",
    "| `Product ID`              | Identifier for the product. |\n",
    "| `Type`                    | The type of the product. |\n",
    "| `Air temperature [K]`     | Ambient air temperature measured in Kelvin. |\n",
    "| `Process temperature [K]` | Temperature of the process, measured in Kelvin. |\n",
    "| `Rotational speed [rpm]`  | Speed at which the machine operates, measured in revolutions per minute. |\n",
    "| `Torque [Nm]`             | The torque produced by the machine, measured in Newton meters. |\n",
    "| `Tool wear [min]`         | The amount of wear on the tool, measured in minutes. |\n",
    "| `Machine failure`         | Indicates if there was a machine failure (1) or not (0). |\n",
    "| `TWF`                     | Tool Wear Failure - Indicates if the failure was due to tool wear. |\n",
    "| `HDF`                     | Heat Dissipation Failure - Indicates if the failure was due to heat dissipation. |\n",
    "| `PWF`                     | Power Failure - Indicates if the failure was due to power failure. |\n",
    "| `OSF`                     | Overstrain Failure - Indicates if the failure was due to overstrain. |\n",
    "| `RNF`                     | Random Failures - Indicates if the failure was random. |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d4b94d0-04c2-4697-86c8-aeb52acb6860",
   "metadata": {},
   "source": [
    "## Data cleaning and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2962e6b2-dba4-457c-9a65-fb9ee54839d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns to replace spaces with underscores\n",
    "for col in df.columns:\n",
    "    df = df.withColumnRenamed(col, col.replace(\" \", \"_\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91ef6895-2349-4dcb-951d-905331c0d425",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    " \n",
    "# Create a new DataFrame with lowercase column names\n",
    "df = df.select([col(column).alias(column.lower()) for column in df.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13324380-b1ab-4d97-b6a6-66522ad6088a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+----+-------------------+-----------------------+----------------------+-----------+---------------+---------------+---+---+---+---+---+\n",
      "|udi|product_id|type|air_temperature_[k]|process_temperature_[k]|rotational_speed_[rpm]|torque_[nm]|tool_wear_[min]|machine_failure|twf|hdf|pwf|osf|rnf|\n",
      "+---+----------+----+-------------------+-----------------------+----------------------+-----------+---------------+---------------+---+---+---+---+---+\n",
      "|  0|         0|   0|                  0|                      0|                     0|          0|              0|              0|  0|  0|  0|  0|  0|\n",
      "+---+----------+----+-------------------+-----------------------+----------------------+-----------+---------------+---------------+---+---+---+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, when, count\n",
    "\n",
    "# Check for missing values in each column\n",
    "missing_values = df.select([count(when(col(c).isNull(), c)).alias(c) for c in df.columns])\n",
    "\n",
    "# Show the missing values for each column\n",
    "missing_values.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be7d4aa0-ba4b-4ef2-a8dc-cb0abcbe9af3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------------------+-----------------------+----------------------+-----------+---------------+---------------+---+---+---+---+---+\n",
      "|type|air_temperature_[k]|process_temperature_[k]|rotational_speed_[rpm]|torque_[nm]|tool_wear_[min]|machine_failure|twf|hdf|pwf|osf|rnf|\n",
      "+----+-------------------+-----------------------+----------------------+-----------+---------------+---------------+---+---+---+---+---+\n",
      "|   M|              298.1|                  308.6|                  1551|       42.8|              0|              0|  0|  0|  0|  0|  0|\n",
      "|   L|              298.2|                  308.7|                  1408|       46.3|              3|              0|  0|  0|  0|  0|  0|\n",
      "|   L|              298.1|                  308.5|                  1498|       49.4|              5|              0|  0|  0|  0|  0|  0|\n",
      "|   L|              298.2|                  308.6|                  1433|       39.5|              7|              0|  0|  0|  0|  0|  0|\n",
      "|   L|              298.2|                  308.7|                  1408|       40.0|              9|              0|  0|  0|  0|  0|  0|\n",
      "|   M|              298.1|                  308.6|                  1425|       41.9|             11|              0|  0|  0|  0|  0|  0|\n",
      "|   L|              298.1|                  308.6|                  1558|       42.4|             14|              0|  0|  0|  0|  0|  0|\n",
      "|   L|              298.1|                  308.6|                  1527|       40.2|             16|              0|  0|  0|  0|  0|  0|\n",
      "|   M|              298.3|                  308.7|                  1667|       28.6|             18|              0|  0|  0|  0|  0|  0|\n",
      "|   M|              298.5|                  309.0|                  1741|       28.0|             21|              0|  0|  0|  0|  0|  0|\n",
      "|   H|              298.4|                  308.9|                  1782|       23.9|             24|              0|  0|  0|  0|  0|  0|\n",
      "|   H|              298.6|                  309.1|                  1423|       44.3|             29|              0|  0|  0|  0|  0|  0|\n",
      "|   M|              298.6|                  309.1|                  1339|       51.1|             34|              0|  0|  0|  0|  0|  0|\n",
      "|   M|              298.6|                  309.2|                  1742|       30.0|             37|              0|  0|  0|  0|  0|  0|\n",
      "|   L|              298.6|                  309.2|                  2035|       19.6|             40|              0|  0|  0|  0|  0|  0|\n",
      "|   L|              298.6|                  309.2|                  1542|       48.4|             42|              0|  0|  0|  0|  0|  0|\n",
      "|   M|              298.6|                  309.2|                  1311|       46.6|             44|              0|  0|  0|  0|  0|  0|\n",
      "|   M|              298.7|                  309.2|                  1410|       45.6|             47|              0|  0|  0|  0|  0|  0|\n",
      "|   H|              298.8|                  309.2|                  1306|       54.5|             50|              0|  0|  0|  0|  0|  0|\n",
      "|   M|              298.9|                  309.3|                  1632|       32.5|             55|              0|  0|  0|  0|  0|  0|\n",
      "+----+-------------------+-----------------------+----------------------+-----------+---------------+---------------+---+---+---+---+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Since 'Product ID' is a unique identifier, we will drop it for modeling purposes\n",
    "df = df.drop('UDI', 'Product_ID')\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16cf6ff7-f975-4b41-9c89-b5410dd56787",
   "metadata": {},
   "source": [
    "# Data Exploration using SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "44b23a8d-830b-4a4a-a9de-7ff5fa880449",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/11/10 03:07:00 WARN HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist\n",
      "23/11/10 03:07:00 WARN HiveConf: HiveConf of name hive.stats.retries.wait does not exist\n",
      "23/11/10 03:07:03 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 2.3.0\n",
      "23/11/10 03:07:03 WARN ObjectStore: setMetaStoreSchemaVersion called but recording version is disabled: version = 2.3.0, comment = Set by MetaStore student@127.0.0.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+-----------+\n",
      "|namespace|           tableName|isTemporary|\n",
      "+---------+--------------------+-----------+\n",
      "|  default|machine_failure_t...|      false|\n",
      "|  default|        movieratings|      false|\n",
      "|  default|              movies|      false|\n",
      "+---------+--------------------+-----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/11/10 03:07:03 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException\n"
     ]
    }
   ],
   "source": [
    "#Lists all the tables that are present in  the environment\n",
    "tables = spark.sql(\"show tables\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d421ebc-43c3-479e-9133-7e8a4a7d655e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Table(name='machine_failure_table', catalog='spark_catalog', namespace=['default'], description=None, tableType='MANAGED', isTemporary=False),\n",
       " Table(name='movieratings', catalog='spark_catalog', namespace=['default'], description=None, tableType='MANAGED', isTemporary=False),\n",
       " Table(name='movies', catalog='spark_catalog', namespace=['default'], description=None, tableType='MANAGED', isTemporary=False)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.catalog.listTables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "adba1c05-9807-4317-a97f-014d7c03d8b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/11/10 03:07:06 WARN SessionState: METASTORE_FILTER_HOOK will be ignored, since hive.security.authorization.manager is set to instance of HiveAuthorizerFactory.\n",
      "23/11/10 03:07:06 WARN HiveConf: HiveConf of name hive.internal.ss.authz.settings.applied.marker does not exist\n",
      "23/11/10 03:07:06 WARN HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist\n",
      "23/11/10 03:07:06 WARN HiveConf: HiveConf of name hive.stats.retries.wait does not exist\n"
     ]
    }
   ],
   "source": [
    "# Drop table if exist and create new table named Machine_Failure_Table\n",
    "spark.sql('drop table if exists Machine_Failure_Table')\n",
    "df.write.saveAsTable('Machine_Failure_Table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a3e16db3-3e33-4b27-87b4-630ee7236974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+-----------+\n",
      "|namespace|           tableName|isTemporary|\n",
      "+---------+--------------------+-----------+\n",
      "|  default|machine_failure_t...|      false|\n",
      "|  default|        movieratings|      false|\n",
      "|  default|              movies|      false|\n",
      "+---------+--------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# THe table is not a temporary table and hence it is showing as false in the below output\n",
    "tables = spark.sql(\"show tables\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "10d45dc2-7f42-4491-93fa-4cf9d2c8ff8e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------------------+-----------------------+----------------------+-----------+---------------+---------------+---+---+---+---+---+\n",
      "|type|air_temperature_[k]|process_temperature_[k]|rotational_speed_[rpm]|torque_[nm]|tool_wear_[min]|machine_failure|twf|hdf|pwf|osf|rnf|\n",
      "+----+-------------------+-----------------------+----------------------+-----------+---------------+---------------+---+---+---+---+---+\n",
      "|   M|              298.1|                  308.6|                  1551|       42.8|              0|              0|  0|  0|  0|  0|  0|\n",
      "|   L|              298.2|                  308.7|                  1408|       46.3|              3|              0|  0|  0|  0|  0|  0|\n",
      "|   L|              298.1|                  308.5|                  1498|       49.4|              5|              0|  0|  0|  0|  0|  0|\n",
      "|   L|              298.2|                  308.6|                  1433|       39.5|              7|              0|  0|  0|  0|  0|  0|\n",
      "|   L|              298.2|                  308.7|                  1408|       40.0|              9|              0|  0|  0|  0|  0|  0|\n",
      "|   M|              298.1|                  308.6|                  1425|       41.9|             11|              0|  0|  0|  0|  0|  0|\n",
      "|   L|              298.1|                  308.6|                  1558|       42.4|             14|              0|  0|  0|  0|  0|  0|\n",
      "|   L|              298.1|                  308.6|                  1527|       40.2|             16|              0|  0|  0|  0|  0|  0|\n",
      "|   M|              298.3|                  308.7|                  1667|       28.6|             18|              0|  0|  0|  0|  0|  0|\n",
      "|   M|              298.5|                  309.0|                  1741|       28.0|             21|              0|  0|  0|  0|  0|  0|\n",
      "|   H|              298.4|                  308.9|                  1782|       23.9|             24|              0|  0|  0|  0|  0|  0|\n",
      "|   H|              298.6|                  309.1|                  1423|       44.3|             29|              0|  0|  0|  0|  0|  0|\n",
      "|   M|              298.6|                  309.1|                  1339|       51.1|             34|              0|  0|  0|  0|  0|  0|\n",
      "|   M|              298.6|                  309.2|                  1742|       30.0|             37|              0|  0|  0|  0|  0|  0|\n",
      "|   L|              298.6|                  309.2|                  2035|       19.6|             40|              0|  0|  0|  0|  0|  0|\n",
      "|   L|              298.6|                  309.2|                  1542|       48.4|             42|              0|  0|  0|  0|  0|  0|\n",
      "|   M|              298.6|                  309.2|                  1311|       46.6|             44|              0|  0|  0|  0|  0|  0|\n",
      "|   M|              298.7|                  309.2|                  1410|       45.6|             47|              0|  0|  0|  0|  0|  0|\n",
      "|   H|              298.8|                  309.2|                  1306|       54.5|             50|              0|  0|  0|  0|  0|  0|\n",
      "|   M|              298.9|                  309.3|                  1632|       32.5|             55|              0|  0|  0|  0|  0|  0|\n",
      "+----+-------------------+-----------------------+----------------------+-----------+---------------+---------------+---+---+---+---+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#select all the fields in the table\n",
    "query1 = spark.sql(\"SELECT * FROM Machine_Failure_Table;\")\n",
    "query1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a6087959-992a-4ee2-aa42-50f5353478c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|   10000|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Select count of all fields\n",
    "query2 = spark.sql(\"SELECT COUNT(*) FROM Machine_Failure_Table;\") # note that this will generate an error\n",
    "query2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eee75b04-103b-4dd1-949e-928a8d5bb52c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------------------+-----------------------+----------------------+-----------+---------------+---------------+---+---+---+---+---+\n",
      "|type|air_temperature_[k]|process_temperature_[k]|rotational_speed_[rpm]|torque_[nm]|tool_wear_[min]|machine_failure|twf|hdf|pwf|osf|rnf|\n",
      "+----+-------------------+-----------------------+----------------------+-----------+---------------+---------------+---+---+---+---+---+\n",
      "|   M|              298.6|                  309.1|                  1339|       51.1|             34|              0|  0|  0|  0|  0|  0|\n",
      "|   H|              298.8|                  309.2|                  1306|       54.5|             50|              0|  0|  0|  0|  0|  0|\n",
      "|   H|              298.9|                  309.2|                  1379|       50.7|            106|              0|  0|  0|  0|  0|  0|\n",
      "|   L|              298.8|                  309.1|                  1350|       52.5|            111|              0|  0|  0|  0|  0|  0|\n",
      "|   L|              298.8|                  309.1|                  1368|       50.8|            115|              0|  0|  0|  0|  0|  0|\n",
      "|   H|              298.8|                  309.2|                  1425|       53.9|            135|              0|  0|  0|  0|  0|  0|\n",
      "|   L|              298.9|                  309.1|                  1383|       54.9|            145|              0|  0|  0|  0|  0|  0|\n",
      "|   L|              298.8|                  309.1|                  1378|       54.4|            165|              0|  0|  0|  0|  0|  0|\n",
      "|   L|              298.8|                  309.1|                  1393|       52.6|            167|              0|  0|  0|  0|  0|  0|\n",
      "|   L|              298.8|                  308.9|                  1398|       51.5|              0|              0|  0|  0|  0|  0|  0|\n",
      "|   M|              299.0|                  309.0|                  1351|       52.2|             44|              0|  0|  0|  0|  0|  0|\n",
      "|   L|              299.0|                  308.8|                  1310|       50.7|            112|              0|  0|  0|  0|  0|  0|\n",
      "|   L|              299.0|                  308.6|                  1329|       60.5|            120|              0|  0|  0|  0|  0|  0|\n",
      "|   L|              298.8|                  308.4|                  1369|       53.0|            138|              0|  0|  0|  0|  0|  0|\n",
      "|   L|              298.7|                  308.6|                  1297|       55.3|            148|              0|  0|  0|  0|  0|  0|\n",
      "|   L|              298.8|                  308.6|                  1268|       55.8|            155|              0|  0|  0|  0|  0|  0|\n",
      "|   H|              298.6|                  308.4|                  1407|       50.5|            164|              0|  0|  0|  0|  0|  0|\n",
      "|   L|              298.4|                  308.3|                  1318|       59.1|             22|              0|  0|  0|  0|  0|  0|\n",
      "|   L|              298.2|                  308.1|                  1462|       50.8|             27|              0|  0|  0|  0|  0|  0|\n",
      "|   L|              298.2|                  308.1|                  1306|       58.3|             35|              0|  0|  0|  0|  0|  0|\n",
      "+----+-------------------+-----------------------+----------------------+-----------+---------------+---------------+---+---+---+---+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Find the rows where the machine failed and the torque was greater than 50 Nm\n",
    "query3 = spark.sql(\"\"\"\n",
    "SELECT * FROM Machine_Failure_Table\n",
    "WHERE Machine_failure = 0 AND `Torque_[Nm]` > 50;\n",
    "\"\"\")\n",
    "query3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5383bae7-ca67-4a7f-9ffd-40de5141264f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------------------+\n",
      "|Type|avg_air_temperature|\n",
      "+----+-------------------+\n",
      "|   M| 300.02926259592965|\n",
      "|   L|  300.0158333333335|\n",
      "|   H|  299.8669990029907|\n",
      "+----+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#average air temperature for each type\n",
    "query4 = spark.sql(\"\"\"\n",
    "SELECT Type, AVG(`Air_temperature_[K]`) AS avg_air_temperature\n",
    "FROM Machine_Failure_Table\n",
    "GROUP BY Type\n",
    "\"\"\")\n",
    "\n",
    "query4.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fb5b7ab2-74a4-4616-bdd9-0ef5a1b54a43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------------------+-----------------------+----------------------+-----------+---------------+---------------+---+---+---+---+---+\n",
      "|type|air_temperature_[k]|process_temperature_[k]|rotational_speed_[rpm]|torque_[nm]|tool_wear_[min]|machine_failure|twf|hdf|pwf|osf|rnf|\n",
      "+----+-------------------+-----------------------+----------------------+-----------+---------------+---------------+---+---+---+---+---+\n",
      "|   M|              298.1|                  308.6|                  1551|       42.8|              0|              0|  0|  0|  0|  0|  0|\n",
      "|   L|              298.2|                  308.7|                  1408|       46.3|              3|              0|  0|  0|  0|  0|  0|\n",
      "|   L|              298.1|                  308.5|                  1498|       49.4|              5|              0|  0|  0|  0|  0|  0|\n",
      "|   L|              298.2|                  308.6|                  1433|       39.5|              7|              0|  0|  0|  0|  0|  0|\n",
      "|   L|              298.2|                  308.7|                  1408|       40.0|              9|              0|  0|  0|  0|  0|  0|\n",
      "|   M|              298.1|                  308.6|                  1425|       41.9|             11|              0|  0|  0|  0|  0|  0|\n",
      "|   L|              298.1|                  308.6|                  1558|       42.4|             14|              0|  0|  0|  0|  0|  0|\n",
      "|   L|              298.1|                  308.6|                  1527|       40.2|             16|              0|  0|  0|  0|  0|  0|\n",
      "|   M|              298.3|                  308.7|                  1667|       28.6|             18|              0|  0|  0|  0|  0|  0|\n",
      "|   M|              298.5|                  309.0|                  1741|       28.0|             21|              0|  0|  0|  0|  0|  0|\n",
      "|   H|              298.4|                  308.9|                  1782|       23.9|             24|              0|  0|  0|  0|  0|  0|\n",
      "|   H|              298.6|                  309.1|                  1423|       44.3|             29|              0|  0|  0|  0|  0|  0|\n",
      "|   M|              298.6|                  309.1|                  1339|       51.1|             34|              0|  0|  0|  0|  0|  0|\n",
      "|   M|              298.6|                  309.2|                  1742|       30.0|             37|              0|  0|  0|  0|  0|  0|\n",
      "|   L|              298.6|                  309.2|                  2035|       19.6|             40|              0|  0|  0|  0|  0|  0|\n",
      "|   L|              298.6|                  309.2|                  1542|       48.4|             42|              0|  0|  0|  0|  0|  0|\n",
      "|   M|              298.6|                  309.2|                  1311|       46.6|             44|              0|  0|  0|  0|  0|  0|\n",
      "|   M|              298.7|                  309.2|                  1410|       45.6|             47|              0|  0|  0|  0|  0|  0|\n",
      "|   H|              298.8|                  309.2|                  1306|       54.5|             50|              0|  0|  0|  0|  0|  0|\n",
      "|   M|              298.9|                  309.3|                  1632|       32.5|             55|              0|  0|  0|  0|  0|  0|\n",
      "+----+-------------------+-----------------------+----------------------+-----------+---------------+---------------+---+---+---+---+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Select all fields where Process temperature is between 300 and 400 Kelvin and the rotational speed is greater than 1000 rpm\n",
    "query5 = spark.sql(\"\"\"\n",
    "SELECT * FROM Machine_Failure_Table\n",
    "WHERE `Process_temperature_[K]` BETWEEN 300 AND 400\n",
    "AND `Rotational_speed_[rpm]` > 1000;\n",
    "\"\"\")\n",
    "\n",
    "query5.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "23943bde-7eec-4443-b8a0-b8aac47fa4eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------------------+\n",
      "|Type|     avg_tool_wear|\n",
      "+----+------------------+\n",
      "|   L|108.37883333333333|\n",
      "|   H|  107.419740777667|\n",
      "|   M|107.27227227227228|\n",
      "+----+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Average tool wear for each type of product\n",
    "query6 = spark.sql(\"\"\"\n",
    "SELECT Type, AVG(`Tool_wear_[min]`) AS avg_tool_wear\n",
    "FROM Machine_Failure_Table\n",
    "GROUP BY Type\n",
    "ORDER BY avg_tool_wear DESC;\n",
    "\"\"\")\n",
    "\n",
    "query6.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0dce95b0-5eee-47fb-a25c-0375be5e72ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+--------------------+------------------+\n",
      "|Machine_failure|avg_rotational_speed|        avg_torque|\n",
      "+---------------+--------------------+------------------+\n",
      "|              1|   1496.486725663717|50.168141592920364|\n",
      "|              0|  1540.2600144912535| 39.62965531518476|\n",
      "+---------------+--------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculating average rotational speed and torque for failed and non-failed machines\n",
    "query7=spark.sql(\"\"\"\n",
    "SELECT \n",
    "    Machine_failure, \n",
    "    AVG(`rotational_speed_[rpm]`) as avg_rotational_speed, \n",
    "    AVG(`torque_[Nm]`) as avg_torque\n",
    "FROM Machine_Failure_Table\n",
    "GROUP BY Machine_failure\n",
    "\"\"\")\n",
    "query7.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1e2a69d6-891a-40b4-86a7-286dfdba4027",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------------------+-----------------------+\n",
      "|Type|avg_air_temperature|avg_process_temperature|\n",
      "+----+-------------------+-----------------------+\n",
      "|   M| 300.02926259592965|      310.0187854521179|\n",
      "|   L|  300.0158333333335|      310.0123000000004|\n",
      "|   H|  299.8669990029907|      309.9257228315058|\n",
      "+----+-------------------+-----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Maximum rotational speed and torque values for records where a machine failure occurred:\n",
    "\n",
    "query8 = spark.sql(\"\"\" SELECT Type, AVG(`air_temperature_[K]`) AS avg_air_temperature, AVG(`process_temperature_[K]`) AS avg_process_temperature\n",
    "FROM Machine_Failure_Table\n",
    "GROUP BY Type;\"\"\")\n",
    "\n",
    "query8.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "26ec53c0-0f77-4f36-9252-7ec75595ba0a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------------------+-----------------------+----------------------+-----------+---------------+---------------+---+---+---+---+---+\n",
      "|type|air_temperature_[k]|process_temperature_[k]|rotational_speed_[rpm]|torque_[nm]|tool_wear_[min]|machine_failure|twf|hdf|pwf|osf|rnf|\n",
      "+----+-------------------+-----------------------+----------------------+-----------+---------------+---------------+---+---+---+---+---+\n",
      "|   M|              298.1|                  308.6|                  1551|       42.8|              0|              0|  0|  0|  0|  0|  0|\n",
      "|   L|              298.2|                  308.7|                  1408|       46.3|              3|              0|  0|  0|  0|  0|  0|\n",
      "|   L|              298.1|                  308.5|                  1498|       49.4|              5|              0|  0|  0|  0|  0|  0|\n",
      "|   L|              298.2|                  308.6|                  1433|       39.5|              7|              0|  0|  0|  0|  0|  0|\n",
      "|   L|              298.2|                  308.7|                  1408|       40.0|              9|              0|  0|  0|  0|  0|  0|\n",
      "|   M|              298.1|                  308.6|                  1425|       41.9|             11|              0|  0|  0|  0|  0|  0|\n",
      "|   L|              298.1|                  308.6|                  1558|       42.4|             14|              0|  0|  0|  0|  0|  0|\n",
      "|   L|              298.1|                  308.6|                  1527|       40.2|             16|              0|  0|  0|  0|  0|  0|\n",
      "|   M|              298.3|                  308.7|                  1667|       28.6|             18|              0|  0|  0|  0|  0|  0|\n",
      "|   M|              298.5|                  309.0|                  1741|       28.0|             21|              0|  0|  0|  0|  0|  0|\n",
      "|   H|              298.4|                  308.9|                  1782|       23.9|             24|              0|  0|  0|  0|  0|  0|\n",
      "|   H|              298.6|                  309.1|                  1423|       44.3|             29|              0|  0|  0|  0|  0|  0|\n",
      "|   M|              298.6|                  309.1|                  1339|       51.1|             34|              0|  0|  0|  0|  0|  0|\n",
      "|   M|              298.6|                  309.2|                  1742|       30.0|             37|              0|  0|  0|  0|  0|  0|\n",
      "|   L|              298.6|                  309.2|                  2035|       19.6|             40|              0|  0|  0|  0|  0|  0|\n",
      "|   L|              298.6|                  309.2|                  1542|       48.4|             42|              0|  0|  0|  0|  0|  0|\n",
      "|   M|              298.6|                  309.2|                  1311|       46.6|             44|              0|  0|  0|  0|  0|  0|\n",
      "|   M|              298.7|                  309.2|                  1410|       45.6|             47|              0|  0|  0|  0|  0|  0|\n",
      "|   H|              298.8|                  309.2|                  1306|       54.5|             50|              0|  0|  0|  0|  0|  0|\n",
      "|   M|              298.9|                  309.3|                  1632|       32.5|             55|              0|  0|  0|  0|  0|  0|\n",
      "+----+-------------------+-----------------------+----------------------+-----------+---------------+---------------+---+---+---+---+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d96456-a5bf-4c1e-aec2-f4ae41c8c50d",
   "metadata": {},
   "source": [
    "# Train_Test_Split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e028d48-e463-4c50-af49-c65547db468b",
   "metadata": {},
   "source": [
    "#### We are only considering the columns type, air_temperature, process_temperature_, rotational_speed_, torque_, tool_wear_ and machine_failure for the train_test split. The columns TWF, HDF, PWF, OSF, RNF indicate specific types of failures. Including these as features would directly give away the answer to whether a machine failure occurred, which is what you're trying to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bd1a0af3-5e69-4abb-b13a-e56bb638957a",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = ['type','air_temperature_[k]','process_temperature_[k]','rotational_speed_[rpm]','torque_[nm]','tool_wear_[min]','machine_failure']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ad9f8af0-6164-4b46-9189-76574ff7f456",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------------------+-----------------------+----------------------+-----------+---------------+---------------+\n",
      "|type|air_temperature_[k]|process_temperature_[k]|rotational_speed_[rpm]|torque_[nm]|tool_wear_[min]|machine_failure|\n",
      "+----+-------------------+-----------------------+----------------------+-----------+---------------+---------------+\n",
      "|   H|              295.5|                  305.9|                  1593|       37.2|            197|              0|\n",
      "|   H|              295.6|                  306.0|                  1396|       52.4|              0|              0|\n",
      "|   H|              295.6|                  306.1|                  1256|       62.3|            142|              0|\n",
      "|   H|              295.6|                  306.1|                  1623|       30.9|            210|              0|\n",
      "|   H|              295.6|                  306.2|                  1329|       55.3|            135|              0|\n",
      "+----+-------------------+-----------------------+----------------------+-----------+---------------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_data,test_data=df.randomSplit([0.7,0.3])\n",
    "train_data = train_data.select(input)\n",
    "test_data = test_data.select(input)\n",
    "train_data.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a63680-2be8-4f0f-9504-4701e0e1cedf",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a8c19b2-761b-47b9-bdce-b4cc8c4483a8",
   "metadata": {},
   "source": [
    "### Data Imbalance issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "238173b8-e8e3-4829-be25-11ab2fa2f518",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-----+\n",
      "|machine_failure|count|\n",
      "+---------------+-----+\n",
      "|              1|  227|\n",
      "|              0| 6713|\n",
      "+---------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "machine_failure_count = train_data.groupBy('machine_failure').count()\n",
    "\n",
    "# Show the result\n",
    "machine_failure_count.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6ac53298-d910-4888-bcc1-ee3e9b3b8cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, explode, array, lit, rand\n",
    "# Separate majority and minority classes\n",
    "major_df = train_data.filter(col('machine_failure') == 0)\n",
    "minor_df = test_data.filter(col('machine_failure') == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ae412690-973a-4393-8e04-2f919fbabf07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59\n"
     ]
    }
   ],
   "source": [
    "# Calculate the oversampling ratio\n",
    "ratio = major_df.count() // minor_df.count()\n",
    "print(ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "703f13f4-9984-4e30-8ccf-e8178599ebe1",
   "metadata": {},
   "source": [
    "#### 65 clearly indicates that the data is imbalanced and need to be sampled to make it balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c3432f90-3e37-42fd-b91c-f3b76954702f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Oversample the minority class\n",
    "# Create an array column with 'ratio' copies of the minority rows\n",
    "oversampled_minor_df = minor_df.withColumn('oversample', explode(array([lit(x) for x in range(ratio)]))).drop('oversample')\n",
    "\n",
    "# Combine the oversampled minority rows with the majority class\n",
    "balanced_df = major_df.unionAll(oversampled_minor_df)\n",
    "\n",
    "# Shuffle the DataFrame (optional but recommended)\n",
    "balanced_df = balanced_df.orderBy(rand())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4683d003-ef82-4eb1-87a1-0dcb13e81e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = balanced_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d58d90-0d2d-447e-b3fc-4d07d7770586",
   "metadata": {},
   "source": [
    "### After performing oversampling, the data seemed to be sampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fb8b3369-df38-4a82-9629-b49dee4d009f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-----+\n",
      "|machine_failure|count|\n",
      "+---------------+-----+\n",
      "|              0| 6713|\n",
      "|              1| 6608|\n",
      "+---------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "machine_failure_count = train_data.groupBy('machine_failure').count()\n",
    "\n",
    "# Show the result\n",
    "machine_failure_count.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bfe25cf-09c2-4948-a53b-bf955fc6600b",
   "metadata": {},
   "source": [
    "### Converting the type variable to an index and encoding it to a vector to pass it as input to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c8f3d478-65cf-47ea-bf76-80c9ee0ce796",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder\n",
    " \n",
    "type_indexer = StringIndexer(inputCol=\"type\", outputCol=\"TypeIndex\")\n",
    "type_encoder = OneHotEncoder(inputCols=[\"TypeIndex\"], outputCols=[\"TypeVec\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a23b527c-d482-4d09-b7d8-c9ff8a0aa093",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "01b5b747-fbe9-4457-9adb-120d82e3f641",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Feature Vectors:\n",
    "\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "# Feature engineering\n",
    "assembler = VectorAssembler(inputCols=[\"TypeVec\", \"air_temperature_[k]\", \"process_temperature_[k]\", \n",
    "                                       \"rotational_speed_[rpm]\", \"torque_[nm]\", \n",
    "                                       \"tool_wear_[min]\"], outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c37bd269-c3be-4959-8353-75aa3c93f6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scale the Continuous Features:\n",
    "\n",
    "from pyspark.ml.feature import StandardScaler\n",
    "\n",
    "scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaledFeatures\", withStd=True, withMean=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "702c23d6-3916-4077-ae2e-31b09da2e405",
   "metadata": {},
   "source": [
    "## Identifying the evaluation metric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3afff1d3-7566-4dab-86f1-f3cabd0931a8",
   "metadata": {},
   "source": [
    "#### In the context of predictive maintenance, where the dataset involves machine operations and potential failures, the primary concern is the cost associated with missing an actual failure (false negative). Not identifying a machine failure in time can lead to unplanned downtime, increased repair costs, safety risks, and significant operational disruptions. Therefore, our objective is to minimize these false negatives as much as possible. This makes recall a crucial metric for our predictive model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5bc140-fdd6-4aaf-82cc-1fc79506d5d2",
   "metadata": {},
   "source": [
    "## Building the Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "074e0773-adc2-46bb-a204-fca5889e55e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "\n",
    "dt_model = DecisionTreeClassifier(labelCol='machine_failure',maxBins=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d70509e1-e5ce-4ffe-97d3-ed7c0d4d737a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(\n",
    "    stages=[\n",
    "        type_indexer,\n",
    "        type_encoder,\n",
    "        assembler,\n",
    "        scaler,\n",
    "        dt_model\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a88aa876-3cd3-4655-a2ad-13092fcd85e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_model=pipe.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "45270f5a-23d2-47cb-bdfd-d8b1e93cb46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = fit_model.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c160792c-a4b2-4b3f-b9db-e44e3365e733",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+----------+\n",
      "|machine_failure|prediction|\n",
      "+---------------+----------+\n",
      "|              0|       0.0|\n",
      "|              0|       0.0|\n",
      "|              0|       0.0|\n",
      "|              0|       0.0|\n",
      "|              0|       0.0|\n",
      "|              0|       0.0|\n",
      "|              0|       0.0|\n",
      "|              0|       0.0|\n",
      "|              0|       0.0|\n",
      "|              0|       0.0|\n",
      "|              0|       0.0|\n",
      "|              0|       0.0|\n",
      "|              0|       0.0|\n",
      "|              0|       0.0|\n",
      "|              1|       1.0|\n",
      "|              0|       0.0|\n",
      "|              0|       0.0|\n",
      "|              0|       0.0|\n",
      "|              0|       0.0|\n",
      "|              0|       0.0|\n",
      "+---------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results.select(['machine_failure','prediction']).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5bf9cb0-fa0d-4448-a827-4e79c04d03ca",
   "metadata": {},
   "source": [
    "### Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "29e982ec-f874-40c9-88a7-40a4efb21868",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The area under the curve is 0.95\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "AUC_evaluator = BinaryClassificationEvaluator(rawPredictionCol='prediction',labelCol='machine_failure',metricName='areaUnderROC')\n",
    "AUC = AUC_evaluator.evaluate(results)\n",
    "\n",
    "print(f\"The area under the curve is {AUC:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea0e3a7-6405-4cb3-b982-39958fff02c9",
   "metadata": {},
   "source": [
    "###  Area Under PR Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "87274130-9738-48a8-8fb1-fbdfdbdbd4cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The area under the PR curve is 0.3542407834844464\n"
     ]
    }
   ],
   "source": [
    "PR_evaluator = BinaryClassificationEvaluator(rawPredictionCol='prediction',labelCol='machine_failure',metricName='areaUnderPR')\n",
    "PR = PR_evaluator.evaluate(results)\n",
    "\n",
    "print(\"The area under the PR curve is {}\".format(PR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "538f25a1-fd2d-40c9-84d2-64d7de2c30bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The recall of the model is 0.9732142857142857\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"machine_failure\", predictionCol=\"prediction\")\n",
    "recall = evaluator.setMetricName(\"recallByLabel\").setMetricLabel(1).evaluate(results)\n",
    "print(f\"The recall of the model is {recall}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e0104329-10b7-4afa-b11f-9ce39e10db9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is the confusion matrix: \n",
      " [[2753  195]\n",
      " [   3  109]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_true = results.select(\"machine_failure\")\n",
    "y_true = y_true.toPandas()\n",
    " \n",
    "y_pred = results.select(\"prediction\")\n",
    "y_pred = y_pred.toPandas()\n",
    " \n",
    "cnf_matrix = confusion_matrix(y_true, y_pred)\n",
    "print(\"Below is the confusion matrix: \\n {}\".format(cnf_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c6638622-62df-4302-99fe-fb7cf4ac112b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tn = cnf_matrix[0][0]\n",
    "fp = cnf_matrix[0][1]\n",
    "fn = cnf_matrix[1][0]\n",
    "tp = cnf_matrix[1][1]\n",
    "\n",
    "accuracy = (tp+tn)/(tp+tn+fp+fn)\n",
    "precision = tp/(tp+fp)\n",
    "recall = tp/(tp+fn)\n",
    "f1_score = 2*(precision*recall)/(precision+recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "89c3a10d-2c65-4a6a-9b2e-4e9be7c31673",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.93529412\n",
      "Precision: 0.35855263\n",
      "Recall: 0.97321429\n",
      "F1 Score: 0.52403846\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy: {accuracy:.8f}\")\n",
    "print(f\"Precision: {precision:.8f}\")\n",
    "print(f\"Recall: {recall:.8f}\")\n",
    "print(f\"F1 Score: {f1_score:.8f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b8fd6c-3cf4-44ff-a13e-c2289ad152e2",
   "metadata": {},
   "source": [
    "## RandomForest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ede7185c-cb32-4ea7-ade2-a29089579593",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "\n",
    "# Creating an object for RandomForest classfication model\n",
    "rf_model = RandomForestClassifier(labelCol=\"machine_failure\", featuresCol=\"features\", numTrees=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "26592e37-61a8-4dee-ab91-4c48828ff9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "\n",
    "pipe_rf = Pipeline(\n",
    "    stages=[\n",
    "        type_indexer,\n",
    "        type_encoder,\n",
    "        assembler,\n",
    "        scaler,\n",
    "        rf_model\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "14b4f648-f284-45ae-91b1-9c8ef7387338",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "rf_model = pipe_rf.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ff80c110-5641-4983-855d-1df22b378ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_rf = rf_model.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "191eb00c-3186-4dfe-b530-26bc4b08a67f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+----------+\n",
      "|machine_failure|prediction|\n",
      "+---------------+----------+\n",
      "|              0|       0.0|\n",
      "|              0|       0.0|\n",
      "|              0|       0.0|\n",
      "|              0|       0.0|\n",
      "|              0|       0.0|\n",
      "|              0|       0.0|\n",
      "|              0|       0.0|\n",
      "|              0|       0.0|\n",
      "|              0|       0.0|\n",
      "|              0|       0.0|\n",
      "|              0|       0.0|\n",
      "|              0|       0.0|\n",
      "|              0|       0.0|\n",
      "|              0|       0.0|\n",
      "|              1|       1.0|\n",
      "|              0|       0.0|\n",
      "|              0|       0.0|\n",
      "|              0|       0.0|\n",
      "|              0|       0.0|\n",
      "|              0|       0.0|\n",
      "+---------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results_rf.select(['machine_failure','prediction']).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7efa0a82-3057-401f-8f1b-768c2a0ae1c5",
   "metadata": {},
   "source": [
    "## Evaluating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f83c2171-d995-44b0-9c4b-71a3b6590520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The area under the curve is 0.94\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "AUC_evaluator = BinaryClassificationEvaluator(rawPredictionCol='prediction',labelCol='machine_failure',metricName='areaUnderROC')\n",
    "AUC = AUC_evaluator.evaluate(results_rf)\n",
    "\n",
    "print(f\"The area under the curve is {AUC:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696eb2f5-ae23-48bf-a9ee-8bddd9fb4fa6",
   "metadata": {},
   "source": [
    "## Area Under PR Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "06d2624b-e459-4e86-aee2-7e73b94b7000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The area under the PR curve is 0.2881100407642732\n"
     ]
    }
   ],
   "source": [
    "PR_evaluator = BinaryClassificationEvaluator(rawPredictionCol='prediction',labelCol='machine_failure',metricName='areaUnderPR')\n",
    "PR = PR_evaluator.evaluate(results_rf)\n",
    "\n",
    "print(\"The area under the PR curve is {}\".format(PR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d6c089c8-8960-4527-ac26-1bd8bb9239c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The recall of the model is 0.9642857142857143\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"machine_failure\", predictionCol=\"prediction\")\n",
    "recall = evaluator.setMetricName(\"recallByLabel\").setMetricLabel(1).evaluate(results_rf)\n",
    "print(f\"The recall of the model is {recall}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7446380b-6431-40b6-98b9-257f40b4d573",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is the confusion matrix: \n",
      " [[2687  261]\n",
      " [   4  108]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_true = results_rf.select(\"machine_failure\")\n",
    "y_true = y_true.toPandas()\n",
    " \n",
    "y_pred = results_rf.select(\"prediction\")\n",
    "y_pred = y_pred.toPandas()\n",
    " \n",
    "cnf_matrix = confusion_matrix(y_true, y_pred)\n",
    "print(\"Below is the confusion matrix: \\n {}\".format(cnf_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "44cddc03-df59-41a3-9e52-a8b6428cabaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "tn = cnf_matrix[0][0]\n",
    "fp = cnf_matrix[0][1]\n",
    "fn = cnf_matrix[1][0]\n",
    "tp = cnf_matrix[1][1]\n",
    "\n",
    "accuracy = (tp+tn)/(tp+tn+fp+fn)\n",
    "precision = tp/(tp+fp)\n",
    "recall = tp/(tp+fn)\n",
    "f1_score = 2*(precision*recall)/(precision+recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0b871108-ac47-4d35-948e-287d49bd9f94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.91339869\n",
      "Precision: 0.29268293\n",
      "Recall: 0.96428571\n",
      "F1 Score: 0.44906445\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy: {accuracy:.8f}\")\n",
    "print(f\"Precision: {precision:.8f}\")\n",
    "print(f\"Recall: {recall:.8f}\")\n",
    "print(f\"F1 Score: {f1_score:.8f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b853cf2-f7cb-4f2c-bbcb-808efd950ef1",
   "metadata": {},
   "source": [
    "## Linear SVC Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "04fc243b-d18e-4574-b0ac-3a1f14b42828",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LinearSVC\n",
    "\n",
    "lsvc_model = LinearSVC(labelCol=\"machine_failure\", featuresCol=\"features\", maxIter=10, regParam=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9efbc094-4f11-451d-9939-ef6cea8ef627",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_svc = Pipeline(\n",
    "    stages=[\n",
    "        type_indexer,\n",
    "        type_encoder,\n",
    "        assembler,\n",
    "        scaler,\n",
    "        lsvc_model\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ce20d5f0-cae3-4b5b-a9d0-a14d05289d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "lsvc_model = pipe_svc.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "add1aef4-9cba-4889-a159-aa4198d5a675",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_svc = lsvc_model.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f9e3e786-f7a6-4941-becc-ee48488dfcb1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+----------+\n",
      "|machine_failure|prediction|\n",
      "+---------------+----------+\n",
      "|              0|       0.0|\n",
      "|              0|       0.0|\n",
      "|              0|       0.0|\n",
      "|              0|       0.0|\n",
      "|              0|       0.0|\n",
      "|              0|       0.0|\n",
      "|              0|       0.0|\n",
      "|              0|       0.0|\n",
      "|              0|       0.0|\n",
      "|              0|       0.0|\n",
      "|              0|       0.0|\n",
      "|              0|       0.0|\n",
      "|              0|       0.0|\n",
      "|              0|       0.0|\n",
      "|              1|       0.0|\n",
      "|              0|       0.0|\n",
      "|              0|       0.0|\n",
      "|              0|       0.0|\n",
      "|              0|       0.0|\n",
      "|              0|       0.0|\n",
      "+---------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results_svc.select(['machine_failure','prediction']).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d2390a4-5112-4b12-a944-9f55587b4be9",
   "metadata": {},
   "source": [
    "## Evaluating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "006fe6de-b517-436f-8cc1-23ec63a3fb3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The area under the curve is 0.79\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "AUC_evaluator = BinaryClassificationEvaluator(rawPredictionCol='prediction',labelCol='machine_failure',metricName='areaUnderROC')\n",
    "AUC = AUC_evaluator.evaluate(results_svc)\n",
    "\n",
    "print(f\"The area under the curve is {AUC:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e348198-eeac-4dde-8aa5-2364e96f3cee",
   "metadata": {},
   "source": [
    "## Area Under PR Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2419b7ae-3179-415f-8c49-feab7f13a13e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The area under the PR curve is 0.1264635704228101\n"
     ]
    }
   ],
   "source": [
    "PR_evaluator = BinaryClassificationEvaluator(rawPredictionCol='prediction',labelCol='machine_failure',metricName='areaUnderPR')\n",
    "PR = PR_evaluator.evaluate(results_svc)\n",
    "\n",
    "print(\"The area under the PR curve is {}\".format(PR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "214ef018-9be8-4cc6-9cc7-218d3d9b107e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The recall of the model is 0.7678571428571429\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"machine_failure\", predictionCol=\"prediction\")\n",
    "recall = evaluator.setMetricName(\"recallByLabel\").setMetricLabel(1).evaluate(results_svc)\n",
    "print(f\"The recall of the model is {recall}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1bfefa9c-5134-4f64-a562-4c8a238b3141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is the confusion matrix: \n",
      " [[2412  536]\n",
      " [  26   86]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_true = results_svc.select(\"machine_failure\")\n",
    "y_true = y_true.toPandas()\n",
    " \n",
    "y_pred = results_svc.select(\"prediction\")\n",
    "y_pred = y_pred.toPandas()\n",
    " \n",
    "cnf_matrix = confusion_matrix(y_true, y_pred)\n",
    "print(\"Below is the confusion matrix: \\n {}\".format(cnf_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4d1d462b-fde5-46bb-bda9-85c4d22a997f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tn = cnf_matrix[0][0]\n",
    "fp = cnf_matrix[0][1]\n",
    "fn = cnf_matrix[1][0]\n",
    "tp = cnf_matrix[1][1]\n",
    "\n",
    "accuracy = (tp+tn)/(tp+tn+fp+fn)\n",
    "precision = tp/(tp+fp)\n",
    "recall = tp/(tp+fn)\n",
    "f1_score = 2*(precision*recall)/(precision+recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4ef848ff-9d9f-4e9d-812f-fe55d65f421f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.816340\n",
      "Precision: 0.138264\n",
      "Recall: 0.767857\n",
      "F1 Score: 0.234332\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy: {accuracy:.6f}\")\n",
    "print(f\"Precision: {precision:.6f}\")\n",
    "print(f\"Recall: {recall:.6f}\")\n",
    "print(f\"F1 Score: {f1_score:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14cac871-cc8e-4497-ae26-fbefab35b762",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "16ae6ed1-ea30-44b4-be81-4195193ce5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "lr_model = LogisticRegression(featuresCol=\"features\", labelCol=\"machine_failure\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a44b4453-527d-4c97-b4d9-3058174b373c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_lr = Pipeline(\n",
    "    stages=[\n",
    "        type_indexer,\n",
    "        type_encoder,\n",
    "        assembler,\n",
    "        #scaler,\n",
    "        lr_model\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4f0c26bf-4c1e-45b3-80ff-e6f660abce33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "lr_model = pipe_lr.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1d3cc73e-c4ee-4f3b-9226-ef53490aaddc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(type='L', air_temperature_[k]=300.0, process_temperature_[k]=309.0, rotational_speed_[rpm]=1709, torque_[nm]=32.1, tool_wear_[min]=79, machine_failure=0)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "48119942-9bd4-4698-a0f3-4ca48d169ade",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('type', 'string'),\n",
       " ('air_temperature_[k]', 'double'),\n",
       " ('process_temperature_[k]', 'double'),\n",
       " ('rotational_speed_[rpm]', 'int'),\n",
       " ('torque_[nm]', 'double'),\n",
       " ('tool_wear_[min]', 'int'),\n",
       " ('machine_failure', 'int')]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d98830f3-b119-4afc-84df-d29944f70245",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_lr = lr_model.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "fff98184-4c33-4cb1-a5df-af3aa47e7313",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+----------+\n",
      "|machine_failure|prediction|\n",
      "+---------------+----------+\n",
      "|              0|       0.0|\n",
      "|              0|       0.0|\n",
      "|              0|       0.0|\n",
      "|              0|       0.0|\n",
      "|              0|       0.0|\n",
      "|              0|       0.0|\n",
      "|              0|       0.0|\n",
      "|              0|       0.0|\n",
      "|              0|       0.0|\n",
      "|              0|       0.0|\n",
      "|              0|       0.0|\n",
      "|              0|       0.0|\n",
      "|              0|       0.0|\n",
      "|              0|       1.0|\n",
      "|              1|       0.0|\n",
      "|              0|       0.0|\n",
      "|              0|       0.0|\n",
      "|              0|       0.0|\n",
      "|              0|       0.0|\n",
      "|              0|       0.0|\n",
      "+---------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results_lr.select(['machine_failure','prediction']).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28148f2a-121c-466c-a747-c0d0675909c9",
   "metadata": {},
   "source": [
    "## Evaluating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "0e8308ab-aa39-4281-b60e-c18fc6632dc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The area under the curve is 0.83\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "AUC_evaluator = BinaryClassificationEvaluator(rawPredictionCol='prediction',labelCol='machine_failure',metricName='areaUnderROC')\n",
    "AUC = AUC_evaluator.evaluate(results_lr)\n",
    "\n",
    "print(f\"The area under the curve is {AUC:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80392816-9562-4421-a7cd-735bef55f1f4",
   "metadata": {},
   "source": [
    "## Area Under PR Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "9fac8207-8f46-444f-92ca-ee8879e9e995",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The area under the PR curve is 0.14614929305055355\n"
     ]
    }
   ],
   "source": [
    "PR_evaluator = BinaryClassificationEvaluator(rawPredictionCol='prediction',labelCol='machine_failure',metricName='areaUnderPR')\n",
    "PR = PR_evaluator.evaluate(results_lr)\n",
    "\n",
    "print(\"The area under the PR curve is {}\".format(PR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a54fd298-54df-474c-a9a8-7b52f7db0f0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The recall of the model is 0.8303571428571429\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"machine_failure\", predictionCol=\"prediction\")\n",
    "recall = evaluator.setMetricName(\"recallByLabel\").setMetricLabel(1).evaluate(results_lr)\n",
    "print(f\"The recall of the model is {recall}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "8acc9df1-c5bc-4022-8043-24a67c6433a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is the confusion matrix: \n",
      " [[2446  502]\n",
      " [  19   93]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_true = results_lr.select(\"machine_failure\")\n",
    "y_true = y_true.toPandas()\n",
    " \n",
    "y_pred = results_lr.select(\"prediction\")\n",
    "y_pred = y_pred.toPandas()\n",
    " \n",
    "cnf_matrix = confusion_matrix(y_true, y_pred)\n",
    "print(\"Below is the confusion matrix: \\n {}\".format(cnf_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "bf80d900-64e2-416c-b368-2aa0fc1ca172",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is the confusion matrix: \n",
      " [[2446  502]\n",
      " [  19   93]]\n",
      "Recall: 0.8303571428571429\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, recall_score\n",
    "\n",
    "y_true = results_lr.select(\"machine_failure\").toPandas()\n",
    "y_pred = results_lr.select(\"prediction\").toPandas()\n",
    "\n",
    "# Calculate confusion matrix\n",
    "cnf_matrix = confusion_matrix(y_true, y_pred)\n",
    "print(\"Below is the confusion matrix: \\n {}\".format(cnf_matrix))\n",
    "\n",
    "# Calculate recall\n",
    "recall = recall_score(y_true, y_pred)\n",
    "print(\"Recall: {}\".format(recall))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ecc73d21-cd4e-43b6-ad5f-7bf6d62dac2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tn = cnf_matrix[0][0]\n",
    "fp = cnf_matrix[0][1]\n",
    "fn = cnf_matrix[1][0]\n",
    "tp = cnf_matrix[1][1]\n",
    "\n",
    "accuracy = (tp+tn)/(tp+tn+fp+fn)\n",
    "precision = tp/(tp+fp)\n",
    "recall = tp/(tp+fn)\n",
    "f1_score = 2*(precision*recall)/(precision+recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a3278729-033c-42ef-afe3-161f201926ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.82973856\n",
      "Precision: 0.15630252\n",
      "Recall: 0.83035714\n",
      "F1 Score: 0.26308345\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy: {accuracy:.8f}\")\n",
    "print(f\"Precision: {precision:.8f}\")\n",
    "print(f\"Recall: {recall:.8f}\")\n",
    "print(f\"F1 Score: {f1_score:.8f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "738f7ab2-8efd-4307-bfbe-8735a2224159",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997e67db-af8f-406f-af0b-eabb607a77c8",
   "metadata": {},
   "source": [
    "Decision Tree: Exhibits excellent performance in terms of recall (0.97), making it highly effective at identifying actual failures, a critical aspect in predictive maintenance. However, its precision is relatively low (0.35), indicating a higher rate of false positives. The AUC of 0.95 is impressive, showing strong discriminative ability. The PR score, though lower (0.35), is balanced by its exceptional recall, making this model highly reliable for detecting failures.\n",
    "\n",
    "Random Forest: \r\n",
    "Shows a slightly lower recall (0.96) compared to the Decision Tree, but still excels in identifying actual failures. Its precision is marginally lower than the Decision Tree, suggesting a similar rate of false positives. With an AUC of 0.94, it's nearly as effective as the Decision Tree in distinguishing between classes. The lower PR score (0.28) is a trade-off for its high recal\n",
    "\n",
    "Linear SVC: \r\n",
    "Presents a significant drop in recall (0.76) compared to the tree-based models, indicating it misses more actual failures. Its precision is also low (0.13), suggesting a higher rate of false positives. The AUC of 0.79 is decent but not outstanding, reflecting moderate discriminative ability. With the lowest PR score (0.12), this model is less effective in this predictive maintenance scenario, where high recall is crucia\n",
    "\n",
    "Logistic Regression: \r\n",
    "Offers a moderate recall of 0.83, better than Linear SVC but not as high as the tree-based models. Its precision is slightly better (0.15), but still on the lower side. An AUC of 0.83 indicates reasonable discriminative ability, while the PR score (0.14) suggests challenges in precision-recall balance. This model provides a middle ground in terms of performance, being more balanced but not excelling in recall as much as the Decision Tree or Random Fores\n",
    "\n",
    "Considering the critical importance of recall in predictive maintenance, the Decision Tree model emerges as the most suitable choice due to its highest recall. It ensures that almost all actual failures are detected, despite its lower precision which can lead to some false positives. The Random Forest model closely follows, offering a similar recall with a slightly better balance in other metrics. The Linear SVC and Logistic Regression, while more balanced in terms of precision and recall, do not meet the high recall requirementt.l.e."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "849ad239-c8b6-4f18-8b00-62afeed4244a",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5baf2d-f700-44cb-8067-ef8a29027b67",
   "metadata": {},
   "source": [
    "In addressing the challenge of minimizing unplanned downtime in manufacturing through predictive maintenance, Decision Tree model is the most effective model with a remarkable 97% recall. This signifies its superior ability to predict and prevent potential machine failures, aligning well with the business objective of optimizing efficiency and minimizing disruptions to production. The DEcision Tree's model deployment is recommended for real-time predictive maintenance, offering a proactive approach to address the critical issue of equipment failures."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
